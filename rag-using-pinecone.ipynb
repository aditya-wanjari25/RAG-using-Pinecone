{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG using Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import openai\n",
    "import langchain\n",
    "import pinecone\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load all env variables\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the PDFs in a directory\n",
    "def read_doc(directory):\n",
    "    file_loader = PyPDFDirectoryLoader(directory)\n",
    "    documents = file_loader.load()\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kb_path = '/Users/aditya/Desktop/Citadel/GenAI/Projects/Rag KBs'\n",
    "docs = read_doc(kb_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the pdfs to chunks - due to restrictions in token size\n",
    "def chunk_data (docs, chunk_size = 800, chunk_overlap=50):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = chunk_size, chunk_overlap = chunk_overlap)\n",
    "    docs = text_splitter.split_documents(docs)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = chunk_data(docs=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/h3/t69v6z3n1j716q4chlh4ckgc0000gn/T/ipykernel_6429/2263740955.py:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings(api_key = os.environ[\"OPENAI_API_KEY\"])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x10c145ca0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x10c2c3ad0>, model='text-embedding-ada-002', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initilaise embedding technique\n",
    "embeddings = OpenAIEmbeddings(api_key = os.environ[\"OPENAI_API_KEY\"])\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration of how embeddings work\n",
    "vectors = embeddings.embed_query(\"Aditya is an AI Engineer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1536"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initilaize Pinecone\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an index\n",
    "index_name = \"langchainvectordb\"\n",
    "\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=1536, # Replace with your model dimensions\n",
    "    metric=\"cosine\", # Replace with your model metric\n",
    "    spec=ServerlessSpec(\n",
    "        cloud=\"aws\",\n",
    "        region=\"us-east-1\"\n",
    "    ) \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the vector store\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1e6eca20-9c5c-4ba4-92a8-c82c4d2c7e77',\n",
       " 'd8e1e4dc-99c1-4191-96d1-39600e301784',\n",
       " '80c710c5-f873-4283-8c5e-672e0a4c83c4',\n",
       " '54a94255-2ef1-4e52-b442-bd29f83dcf40',\n",
       " '47fd9635-58cb-4c6a-ab0d-283eb419470c',\n",
       " '4ceb06bc-b0d8-47c0-8290-a905d3b027c8',\n",
       " '9ec3881a-0077-4a81-9b4c-a51281afecd1',\n",
       " '8cbc88a5-9b85-4b1f-80f5-69aed3b7896b',\n",
       " '686e9643-a3fa-45f9-b8c6-12be54e0bf7b',\n",
       " 'b7608a98-0f85-42f1-8537-b78e59f0ebcc',\n",
       " 'd87afa35-7d44-43d9-9e5d-75e7e21f94c2',\n",
       " 'a0f3d5cd-2234-407f-b3a8-14b3cc927a11',\n",
       " '51dd9f80-5c25-4432-838a-c8e9f973ea2d',\n",
       " '6a282430-ba41-43a2-a1a7-34abe1b41a46',\n",
       " '674ebbfa-8c56-4c73-ae3b-fa9649659f59',\n",
       " 'dc3aa596-071b-44c2-aa33-959ceec498ff',\n",
       " '04a53ebd-a0cf-47dd-8a60-bcc54c44eb83',\n",
       " 'de3f26e5-6ca7-4655-8c80-8d4955420dfa',\n",
       " '389b0dbd-4913-407b-bdb8-d1ea5a40c5b0',\n",
       " '1173c9b5-08ba-407e-84b6-cec9c051a254',\n",
       " 'ec40423c-fa38-45f0-9ff1-e77f2c5345b4',\n",
       " '07f86581-bd62-4ea5-950b-0c333ed1afc1',\n",
       " '98191f29-d854-4446-b4c9-642b35f7372e',\n",
       " 'd49b0878-500a-4a80-b659-c522965cf920',\n",
       " '9fb8d9b2-8692-47e3-8e41-f12f5d1795fa',\n",
       " '4f0ef66d-68c5-433b-80f0-64953cc29737',\n",
       " '3427a316-65a1-47d7-8af9-b1b7c4905371',\n",
       " '3d3e00b2-de87-40d2-afbe-2d9997e2aeee',\n",
       " '8639f72e-13df-489c-af33-789bc1402938',\n",
       " '260cabc8-c982-4489-9b64-98f362ccadaf',\n",
       " 'a9abc723-1c86-4e67-bc1a-e874966bb616',\n",
       " '5b06d83c-9e19-4cb6-bdfc-e9ba7dc77325',\n",
       " '5c67119a-36ba-4f6e-ab9f-e2440c8cb046',\n",
       " '8e5aca72-c3e6-4f9a-9583-fdc56470f659',\n",
       " '541d1ca6-ee24-4d06-9080-c02506bd4271',\n",
       " 'ccf5731b-d2c9-41e7-9b47-351606256045',\n",
       " 'c1758a5c-08d6-4506-b0e3-f3d936a52b6d',\n",
       " '6630c099-f452-49de-9868-e7faa3b2ea2c',\n",
       " '8798e9ce-b6e2-4148-b994-2f7dcf67e6a5',\n",
       " 'bdc0926e-70ef-460e-b92f-51fade221939',\n",
       " '651b03de-10cf-4b6b-9c1b-0ad03f768681',\n",
       " '4c9b859d-95e7-4f49-998d-bcbe47beb230',\n",
       " 'e744667f-c73d-4f55-850b-f0f42cf1d559',\n",
       " 'b5b353c0-4e9a-4a9c-b4bc-2b859751c927',\n",
       " '50ea73ef-39bd-4d51-ad9b-6ffbd7d835f4',\n",
       " 'bb8672f8-d08c-488e-8ecc-42046487baf4',\n",
       " 'f90d360a-2c98-4793-8a87-913b643b2e91',\n",
       " '34266551-d7ed-4584-bf60-a759a7ec3c2e',\n",
       " 'c020e003-1a98-4c66-a79e-3389d1e5c277',\n",
       " 'bb397047-c9bf-4055-b4fc-087f000881d0',\n",
       " '7b5fba89-f3fa-46ce-997b-fecf5516a3c2',\n",
       " '6621fe7e-e3c6-4a4b-ac74-5b7b4fc4a5f4',\n",
       " 'ee009e9d-3cd4-48e4-be34-3db4fd953101',\n",
       " '5df77aa2-601f-4ab6-baf6-ebe02bbe6d16',\n",
       " 'af9012e9-d04c-4908-8786-3e7d6cea004d',\n",
       " '60160b3c-5415-4cbf-9064-122975db678b',\n",
       " '61f456e7-0763-40eb-9e56-4e6b069b55c3',\n",
       " '701001ef-4502-442f-bd6f-57161f65ffec',\n",
       " '344de054-6779-476e-ae3a-1ba37246c02c',\n",
       " 'bb0e091a-0f9b-41b5-a697-37fb1570a0d5',\n",
       " 'f490c753-582f-4662-adf0-c08e3fb575d8',\n",
       " 'f200692b-2feb-41dd-8ec9-bb23d2635dd6']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add document chunks to vector store\n",
    "vector_store.add_documents(documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create retriever\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_kwargs={\n",
    "        \"k\": 3,  # Number of documents to retrieve\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Self-attention, sometimes called intra-attention, is an attention mechanism relating different positions of a single sequence in order to compute a representation of the sequence.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 32, 'prompt_tokens': 1185, 'total_tokens': 1217, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-7ee21152-c9fc-414e-b685-c27a4fc6545a-0' usage_metadata={'input_tokens': 1185, 'output_tokens': 32, 'total_tokens': 1217, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "# set-up your LM\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Create a RAG chain\n",
    "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", api_key = os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "# Create the RAG chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# Invoke the chain\n",
    "response = rag_chain.invoke(\"What is self attention?\")\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
